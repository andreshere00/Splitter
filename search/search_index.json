{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#splitter","title":"Splitter","text":""},{"location":"#overview","title":"Overview","text":"<p>The Splitter application aims to convert documents into markdown format, and split them into chunks using various splitting strategies. The architecture consists of three main pieces: the <code>ReadManager</code>, the <code>SplitManager</code> and the <code>ChunkManager</code>. Observe the following diagram:</p> <p></p>"},{"location":"#how-to-launch-the-application","title":"How to launch the application","text":"<p>The application is exposed via:</p> <ul> <li>REST API</li> <li>CLI</li> </ul>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<p>The following tools and packages are needed to execute the application:</p> <ul> <li>\ud83d\udc0d Python with <code>make</code>. <code>$PYTHONPATH</code> may be set in the <code>.env</code> file.</li> <li>\ud83d\udc0b Docker.</li> </ul> <p>To install all the dependencies, you can use <code>make install</code>.</p> <pre><code>make install\n</code></pre> <p>This application uses <code>uv</code> as dependency management tool, if not installed, use the following command:</p> <pre><code>make install-uv\n</code></pre>"},{"location":"#api","title":"API","text":"<p>The API is accessed through a FastAPI application. This application can be launched executing:</p> <pre><code>make serve\n</code></pre> <p>Application will be accessible through the browser at the host <code>0.0.0.0:8000/docs</code>. Port can be modified through Makefile.</p>"},{"location":"#api-definition-api","title":"API Definition {#api}","text":""},{"location":"#input","title":"Input","text":""},{"location":"#input_1","title":"Input","text":"<p>Object: <code>class &lt;ChunkRequest&gt;</code></p> <pre><code>document_name: Optional[str] = None\ndocument_path: str\ndocument_id: Optional[str] = None\nocr_method: OCRMethodEnum\nsplit_method: SplitMethodEnum\nocr_method: OCRMethodEnum\nsplit_method: SplitMethodEnum\nsplit_params: Optional[Dict[str, Any]] = None\nmetadata: Optional[List[str]] = []\n</code></pre>"},{"location":"#output","title":"Output","text":"<p>Object: <code>class &lt;ChunkResponse&gt;</code></p> <pre><code>chunks: List[str]\nchunk_id: List[str]\nchunk_path: str\ndocument_id: str\ndocument_name: Optional[str] = None\nocr_method: OCRMethodEnum\nsplit_method: SplitMethodEnum\nocr_method: OCRMethodEnum\nsplit_method: SplitMethodEnum\nsplit_params: Optional[Dict[str, Any]] = None\nmetadata: Optional[List[str]] = []\n</code></pre>"},{"location":"#cli","title":"CLI","text":"<p>The application is accessible through Command Line Interface (CLI) using the following command:</p> <pre><code>make run\n</code></pre> <p>This command executes <code>python src/application/cli.py</code> with the configuration provided in <code>config.yaml</code>. See the structure of this configuration file in the next section.</p>"},{"location":"#docker","title":"Docker","text":"<p>The API-interface can be launched using Docker with the following Make commands:</p> <p>Build the image:</p> <pre><code>make docker-api-build # build the image\n</code></pre> <p>Run the image:</p> <pre><code>make docker-api-run # run the image\n</code></pre> <p>Application will be accessible through the browser at the host <code>0.0.0.0:8080/docs</code>. </p> <p>These values are configurable through the following environment variables:</p> <pre><code>PORT=8080\nHOST=0.0.0.0\nLOG_LEVEL=info\n</code></pre> <p>Many other commands are available (use <code>make help</code> to consult):</p> <pre><code>  make docs             - Run the documentation server.\n  make install          - Install application dependencies using uv.\n  make install-uv       - Install uv CLI (OS-specific).\n  make run              - Execute the application using uv.\n  make serve            - Serve the FastAPI application.\n  make docker-api-build - Build the API dockerized application.\n  make docker-api-run   - Run the API dockerized application.\n  make test             - Run tests using uv and pytest.\n  make shell            - Run a uv shell.\n  make pre-commit       - Install pre-commit hooks.\n  make format           - Run pyupgrade, isort, black and flake8 for code style.\n  make clean            - Clean output, cache and log files.\n  make clean-cache      - Clean cache files.\n  make clean-data       - Clean output data files.\n  make clean-log        - Clean log files.\n  make remove-data      - Remove data presented in the output folder.\n</code></pre> <p>Many other commands are available (use <code>make help</code> to consult):</p> <pre><code>  make docs             - Run the documentation server.\n  make install          - Install application dependencies using uv.\n  make install-uv       - Install uv CLI (OS-specific).\n  make run              - Execute the application using uv.\n  make serve            - Serve the FastAPI application.\n  make docker-api-build - Build the API dockerized application.\n  make docker-api-run   - Run the API dockerized application.\n  make test             - Run tests using uv and pytest.\n  make shell            - Run a uv shell.\n  make pre-commit       - Install pre-commit hooks.\n  make format           - Run pyupgrade, isort, black and flake8 for code style.\n  make clean            - Clean output, cache and log files.\n  make clean-cache      - Clean cache files.\n  make clean-data       - Clean output data files.\n  make clean-log        - Clean log files.\n  make remove-data      - Remove data presented in the output folder.\n</code></pre>"},{"location":"#configuration-config","title":"Configuration {#config}","text":"<p>File handling, splitting methods and application settings can be modified using a configuration file. This file is provided in <code>config.yaml</code> file. Otherwise, parameters can be passed as API parameters. The config file has the following structure by default:</p> <pre><code># 1. File I/O Configuration\nfile_io:\n  input_path: \"data/input\"     # Where the application reads files from\n  output_path: \"data/output\"   # Where the application saves the results\n\n# 2. Logging Configuration\nlogging:\n  enabled: true                # Set to false to disable logging\n  level: \"INFO\"                # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL\n  format: \"%(asctime)s - %(levelname)s - %(message)s\"\n  handlers:\n    - type: \"stream\"\n    - type: \"file\"\n      filename: \"logs/app.log\"\n      mode: \"a\"\n\na\n# 3. Splitting Methods Configuration\nsplitter:\n  method: \"recursive\"\n\n  methods:\n    word:\n      num_words: 100  # Number of words in each chunk\n\n    sentence:\n      num_sentences: 5  # Number of sentences in each chunk\n\n    paragraph:\n      num_paragraphs: 3  # Number of paragraphs in each chunk\n\n    # semantic:\n    #   language_model: \"bert-base-uncased\"  # For semantic similarity\n    #   overlap: 0.2                         # Overlap ratio between chunks\n    # semantic:\n    #   language_model: \"bert-base-uncased\"  # For semantic similarity\n    #   overlap: 0.2                         # Overlap ratio between chunks\n\n    fixed:\n      size: 100  # Number of characters per chunk\n\n    # paged:\n    #   num_pages: 1  # Number of pages in each chunk\n    #   overlap: 0.1  # Overlap (in pages) between chunks\n    # paged:\n    #   num_pages: 1  # Number of pages in each chunk\n    #   overlap: 0.1  # Overlap (in pages) between chunks\n\n    recursive:\n      size: 10000     # Characters per chunk\n      overlap: 1000   # Overlapping characters\n\n    # row-column:\n    #   num_columns: 2\n    #   column_names: [\"Column1\", \"Column2\"]\n    #   num_rows: 5\n    #   row_names: [\"Row1\", \"Row2\"]\n    # row-column:\n    #   num_columns: 2\n    #   column_names: [\"Column1\", \"Column2\"]\n    #   num_rows: 5\n    #   row_names: [\"Row1\", \"Row2\"]\n\n    # schema-based:\n    #   num_registers: 50  # Number of registers (or rows) per chunk\n    #   overlap: 5         # Overlapping registers\n    # schema-based:\n    #   num_registers: 50  # Number of registers (or rows) per chunk\n    #   overlap: 5         # Overlapping registers\n\n    # auto:\n    #   fallback_method: \"paragraph\"\n    #   chunk_size: 500\n    #   overlap: 100\n\n# 4. OCR configuration\nocr:\n  method: \"azure\"  # Options: azure, openai, none\n  # include_image_blobs: false\n  # include_json_structure: false\n</code></pre> <ol> <li>Input and output definition: input and output paths can be defined in the section <code>file_io</code>. </li> <li>Logging configuration: it follows a standard convention. It is used only in CLI application.</li> <li>Splitter configuration: several splitting methods can be used according to the following table. The splitting method to be used along with their parameters can be selected in this section.</li> <li>OCR configuration: if needed, an OCR model can be passed to analyze images and extract descriptions. Three options available: <code>none</code>, <code>openai</code>, <code>azure</code>.</li> </ol> <p>Note that when using API, configuration will be provided as parameters. See API definition.</p>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#1-read-manager","title":"1. Read Manager","text":"<ul> <li>Responsible for reading input documents.</li> <li>Supports local file formats: <code>txt</code>, <code>md</code>, ~~<code>doc</code>~~, <code>docx</code>, ~~<code>xls</code>~~, <code>xlsx</code>, <code>pdf</code>, ~~<code>ppt</code>~~, <code>pptx</code>, ~~<code>json</code>~~, ~~<code>yaml</code>~~.</li> <li>If required, OCR can be applied to extract text from scanned documents (<code>OpenAI</code>, <code>AzureOpenAI</code>, ~~<code>Textract</code>~~, ~~<code>Mistral</code>~~, ~~<code>Custom</code>~~). </li> </ul>"},{"location":"#2-split-manager-split","title":"2. Split Manager {#split}","text":"<ul> <li>Splits text into meaningful chunks based on different strategies.</li> <li>Includes the following methods:</li> </ul> Splitter Name Description Parameters Compatible Formats Word Splitter Splits text into words. Input data, number of words in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Sentence Splitter Splits text into sentences. Input data, number of sentences in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Paragraph Splitter Splits text into paragraphs. Input data, number of paragraphs in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Semantic Splitter Splits text based on semantic similarity, using a language model. Input data, language model, overlap. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Fixed Splitter Splits text into a fixed number of words or characters. Input data, number of characters in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Word Splitter Splits text into words. Input data, number of words in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Sentence Splitter Splits text into sentences. Input data, number of sentences in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Paragraph Splitter Splits text into paragraphs. Input data, number of paragraphs in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Semantic Splitter Splits text based on semantic similarity, using a language model. Input data, language model, overlap. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Fixed Splitter Splits text into a fixed number of words or characters. Input data, number of characters in each chunk. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Paged Splitter Splits text into pages. Input data, number of pages in each chunk, overlap. <code>docx</code>, <code>pdf</code>, <code>xls</code>, <code>xlsx</code>, <code>ppt</code>, <code>pptx</code> Recursive Splitter Splits based on a specified chunk size with overlap. Input data, number of characters in each chunk, overlap parameter. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Recursive Splitter Splits based on a specified chunk size with overlap. Input data, number of characters in each chunk, overlap parameter. <code>txt</code>, <code>markdown</code>, <code>docx</code>, <code>pdf</code>, <code>ppt</code>, <code>pptx</code>, <code>.jpg</code>, <code>.png</code> Row-Column Splitter Splits table content by rows or columns. Input data, number of columns, column names, number of rows, row names. <code>xlsx</code>, <code>xls</code>, <code>json</code>, <code>yaml</code> Schema-based Splitter Splits a hierarchical schema while preserving headers. Input data, number of registers, overlap. <code>json</code>, <code>yaml</code>, <code>xml</code>, <code>xls</code>, <code>xlsx</code>, <code>ppt</code>, <code>pptx</code> Auto Splitter Combines multiple splitting methods based on document content. Input data, number of characters in each chunk, overlap. All formats"},{"location":"#chunk-manager","title":"Chunk Manager","text":"<p>Saves the generated chunks from Chunk Manager.</p> <p>Features:</p> <ul> <li>Aggregator: Groups related chunks.</li> <li>Markdown conversion: Converts text into Markdown format.</li> <li>Error handling: Ensures smooth chunking.</li> </ul>"},{"location":"#scenario","title":"Scenario","text":"<p>This application compose a piece of an ambicious project named \"MultiRAG\". This system aims to be a super modullarizable and open-source RAG system which is fully customizable piece by piece. Observe the following architecture diagram:</p> <p>MultiRAG architecture</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>.\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 Dockerfile.api\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 input\n\u2502   \u251c\u2500\u2500 output\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u251c\u2500\u2500 input\n\u2502       \u2502   \u251c\u2500\u2500 test_1.docx\n\u2502       \u2502   \u251c\u2500\u2500 test_1.md\n\u2502       \u2502   \u251c\u2500\u2500 test_1.pdf\n\u2502       \u2502   \u251c\u2500\u2500 test_1.pptx\n\u2502       \u2502   \u251c\u2500\u2500 test_1.txt\n\u2502       \u2502   \u2514\u2500\u2500 test_1.xlsx\n\u2502       \u2514\u2500\u2500 output\n\u251c\u2500\u2500 docker-compose.yaml\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 assets\n\u2502   \u2502   \u251c\u2500\u2500 MultiRAG.drawio.svg\n\u2502   \u2502   \u251c\u2500\u2500 splitter.drawio.svg\n\u2502   \u2502   \u251c\u2500\u2500 splitter.drawio_v0.1.0.drawio.svg\n\u2502   \u2502   \u2514\u2500\u2500 splitter_v0.3.0.drawio.svg\n\u2502   \u251c\u2500\u2500 chunker\n\u2502   \u2502   \u2514\u2500\u2500 docs.md\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 reader\n\u2502   \u2502   \u2514\u2500\u2500 docs.md\n\u2502   \u2514\u2500\u2500 splitter\n\u2502       \u2514\u2500\u2500 docs.md\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 scripts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 build_docs.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 conftest.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 enrich_readme.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 validate_commit_msg.py\n\u251c\u2500\u2500 src\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 application\n\u2502   \u2502   \u251c\u2500\u2500 api\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 app.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 routers\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 health.py\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 split.py\n\u2502   \u2502   \u2514\u2500\u2500 cli.py\n\u2502   \u251c\u2500\u2500 chunker\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 chunk_manager.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 model\n\u2502   \u2502   \u251c\u2500\u2500 base_client.py\n\u2502   \u2502   \u251c\u2500\u2500 llm_client.py\n\u2502   \u2502   \u2514\u2500\u2500 models\n\u2502   \u2502       \u251c\u2500\u2500 azure_client.py\n\u2502   \u2502       \u251c\u2500\u2500 openai_client.py\n\u2502   \u2502       \u2514\u2500\u2500 textract_client.py\n\u2502   \u251c\u2500\u2500 reader\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base_reader.py\n\u2502   \u2502   \u251c\u2500\u2500 read_manager.py\n\u2502   \u2502   \u2514\u2500\u2500 readers\n\u2502   \u2502       \u251c\u2500\u2500 custom_reader.py\n\u2502   \u2502       \u251c\u2500\u2500 docling_reader.py\n\u2502   \u2502       \u251c\u2500\u2500 markitdown_reader.py\n\u2502   \u2502       \u251c\u2500\u2500 ocr_reader.py\n\u2502   \u2502       \u251c\u2500\u2500 pdfplumber_reader.py\n\u2502   \u2502       \u2514\u2500\u2500 textract_reader.py\n\u2502   \u251c\u2500\u2500 splitter\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base_splitter.py\n\u2502   \u2502   \u251c\u2500\u2500 split_manager.py\n\u2502   \u2502   \u2514\u2500\u2500 splitters\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 auto_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 fixed_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 paged_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 paragraph_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 recursive_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 row_column_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 schema_based_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 semantic_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 sentence_splitter.py\n\u2502   \u2502       \u2514\u2500\u2500 word_splitter.py\n\u2502   \u2514\u2500\u2500 utils\n\u2502       \u251c\u2500\u2500 config_loader.py\n\u2502       \u2514\u2500\u2500 logging_manager.py\n\u251c\u2500\u2500 test\n\u2502   \u251c\u2500\u2500 application\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 api\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 routers\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 test_health.py\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 test_split.py\n\u2502   \u2502       \u2514\u2500\u2500 test_app.py\n\u2502   \u251c\u2500\u2500 chunker\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 test_chunk_manager.py\n\u2502   \u251c\u2500\u2500 model\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_azure_client.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_openai_client.py\n\u2502   \u2502   \u2514\u2500\u2500 test_llm_client.py\n\u2502   \u251c\u2500\u2500 reader\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 readers\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_markitdown_reader.py\n\u2502   \u2502   \u2514\u2500\u2500 test_read_manager.py\n\u2502   \u251c\u2500\u2500 splitter\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 splitters\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 test_fixed_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 test_paragraph_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 test_recursive_splitter.py\n\u2502   \u2502       \u251c\u2500\u2500 test_sentence_splitter.py\n\u2502   \u2502       \u2514\u2500\u2500 test_word_splitter.py\n\u2502   \u2514\u2500\u2500 utils\n\u2502       \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 uv.lock\n</code></pre>"},{"location":"#contact","title":"Contact","text":"<ul> <li>E-mail: andresherencia2000@gmail.com.</li> <li>LinkedIn: link</li> </ul>"},{"location":"api/docs/","title":"Application Program Interface (API)","text":"<p>This section documents the FastAPI application and its endpoints.</p>"},{"location":"api/docs/#app-entry-point","title":"App Entry Point","text":"<p>members: false</p>"},{"location":"api/docs/#src.application.api.app.root","title":"<code>root()</code>","text":"<p>Root endpoint for the API.</p> Source code in <code>src/application/api/app.py</code> <pre><code>@app.get(\"/\", tags=[\"System\"])\ndef root():\n    \"\"\"\n    Root endpoint for the API.\n    \"\"\"\n    return {\"message\": \"Document Splitter API is running\"}\n</code></pre>"},{"location":"api/docs/#document-splitting-endpoint","title":"Document Splitting Endpoint","text":"<p>A class containing the document splitting endpoint. Use the <code>split_document</code> method to split documents into chunks.</p> Source code in <code>src/application/api/routers/split.py</code> <pre><code>class SplitAPI:\n    \"\"\"\n    A class containing the document splitting endpoint.\n    Use the `split_document` method to split documents into chunks.\n    \"\"\"\n\n    @staticmethod\n    @router.post(\n        \"/split\",\n        response_model=ChunkResponse,\n        summary=\"Split Document\",\n        description=(\n            \"Splits a document into chunks using the specified split method. \"\n            \"You can either upload a file or specify a file path. \"\n            \"It has an OCR feature to analyze images from the documents. \"\n            \"Optionally, the result can be returned as a ZIP file.\"\n        ),\n    )\n    async def split_document(\n        file: Optional[Union[UploadFile, str]] = File(\n            None, description=\"Uploaded file. Leave empty if using a file path.\"\n        ),\n        document_path: str = Form(\n            \"data/input\",\n            description=\"Absolute or relative path where the document is located.\",\n        ),\n        document_name: str = Form(\n            \"\",\n            description=\"Name for the document; if empty, the uploaded file's name is used.\",\n        ),\n        document_id: str = Form(\n            \"\",\n            description=\"Optional document identifier. If empty, one will be generated.\",\n        ),\n        split_method: SplitMethodEnum = Form(\n            ..., description=\"Method to split the document text.\"\n        ),\n        ocr_method: OCRMethodEnum = Form(\n            ...,\n            description=\"OCR client to use for image processing: 'none', 'openai', or 'azure'.\",\n        ),\n        metadata: Optional[List[str]] = Form([], description=\"Optional metadata tags.\"),\n        split_params: str = Form(\n            \"{}\",\n            description=\"JSON string of custom parameters for splitting (must be a JSON object).\",\n        ),\n        chunk_path: str = Form(\n            \"data/output\", description=\"Path where the output chunks will be stored.\"\n        ),\n        download_zip: bool = Form(\n            False,\n            description=\"If true, returns the chunks in a ZIP archive instead of JSON.\",\n        ),\n    ) -&gt; Union[ChunkResponse, StreamingResponse]:\n        \"\"\"\n        Splits a document into chunks and returns the results.\n\n        Returns:\n            Union[ChunkResponse, StreamingResponse]: A JSON response or ZIP archive with chunks.\n        \"\"\"\n        try:\n            # Normalize paths.\n            document_path = os.path.abspath(document_path)\n            chunk_path = os.path.abspath(chunk_path)\n\n            if isinstance(file, str) and not file.strip():\n                file = None\n\n            # Create unique identifiers.\n            now = datetime.datetime.now()\n            date_str = now.strftime(\"%Y%m%d\")\n            time_str = now.strftime(\"%H%M%S\")\n            uuid_str = uuid.uuid4().hex[:16]\n\n            # Determine file name and directory.\n            if file is not None:\n                file_name = document_name.strip() or file.filename\n                file_dir = document_path\n            else:\n                if not os.path.exists(document_path):\n                    raise HTTPException(\n                        status_code=400,\n                        detail=\"No file provided and document_path does not exist.\",\n                    )\n                file_name = document_name.strip() or os.path.basename(document_path)\n                file_dir = os.path.dirname(document_path)\n\n            # Generate document_id if not provided.\n            if not document_id.strip():\n                document_id = f\"{uuid_str}_{date_str}_{time_str}_{file_name}\"\n\n            os.makedirs(chunk_path, exist_ok=True)\n\n            # Parse custom split parameters.\n            try:\n                custom_split_params = json.loads(split_params)\n                if not isinstance(custom_split_params, dict):\n                    raise ValueError(\"split_params must be a JSON object\")\n                if not custom_split_params:\n                    custom_split_params = None\n            except Exception as e:\n                raise HTTPException(\n                    status_code=400, detail=f\"Invalid split_params: {e}\"\n                )\n\n            base_config = {\"splitter\": {\"method\": split_method.value}}\n            if custom_split_params:\n                base_config[\"splitter\"][\"methods\"] = {\n                    split_method.value: custom_split_params\n                }\n\n            # Prepare ReadManager configuration.\n            read_config = {\n                \"file_io\": {\"input_path\": file_dir},\n                \"ocr\": {\"method\": ocr_method.value},\n            }\n\n            # Instantiate managers.\n            read_manager = ReadManager(config=read_config)\n            split_manager = SplitManager(config=base_config)\n            chunk_manager = ChunkManager(\n                input_path=file_dir,\n                output_path=chunk_path,\n                split_method=split_method.value,\n            )\n\n            # Read document content.\n            markdown_text = (\n                read_manager.read_file_object(file)\n                if file is not None\n                else read_manager.read_file(file_name)\n            )\n\n            chunks = split_manager.split_text(markdown_text)\n            if not chunks:\n                raise HTTPException(\n                    status_code=400, detail=\"No chunks generated from the document.\"\n                )\n\n            chunk_manager.save_chunks(\n                chunks, file_name, os.path.splitext(file_name)[1], split_method.value\n            )\n\n            chunk_ids = [\n                f\"{file_name}_{date_str}_{time_str}_chunk_{i}\"\n                for i in range(1, len(chunks) + 1)\n            ]\n\n            if download_zip:\n                zip_io = io.BytesIO()\n                with zipfile.ZipFile(\n                    zip_io, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n                ) as zip_file:\n                    for i, chunk in enumerate(chunks, start=1):\n                        chunk_filename = (\n                            f\"{os.path.splitext(file_name)[0]}_chunk_{i}.txt\"\n                        )\n                        zip_file.writestr(chunk_filename, chunk)\n                zip_io.seek(0)\n                headers = {\n                    \"Content-Disposition\": f\"attachment; filename={os.path.splitext(file_name)[0]}_chunks.zip\"  # noqa: E501, E261\n                }\n                return StreamingResponse(\n                    zip_io, media_type=\"application/zip\", headers=headers\n                )\n\n            return ChunkResponse(\n                chunks=chunks,\n                chunk_id=chunk_ids,\n                chunk_path=chunk_path,\n                document_id=document_id,\n                document_name=file_name,\n                split_method=split_method.value,\n                metadata=metadata,\n                split_params=custom_split_params,\n                ocr_method=ocr_method,\n            )\n\n        except HTTPException as http_exc:\n            print(\"HTTPException encountered:\", http_exc.detail)\n            raise http_exc\n        except Exception as e:\n            print(\"Unhandled error encountered:\", e)\n            raise HTTPException(status_code=400, detail=f\"Unhandled error: {e}\")\n</code></pre> <p>members: false</p>"},{"location":"api/docs/#src.application.api.routers.split.SplitAPI.split_document","title":"<code>split_document(file=File(None, description='Uploaded file. Leave empty if using a file path.'), document_path=Form('data/input', description='Absolute or relative path where the document is located.'), document_name=Form('', description=\"Name for the document; if empty, the uploaded file's name is used.\"), document_id=Form('', description='Optional document identifier. If empty, one will be generated.'), split_method=Form(..., description='Method to split the document text.'), ocr_method=Form(..., description=\"OCR client to use for image processing: 'none', 'openai', or 'azure'.\"), metadata=Form([], description='Optional metadata tags.'), split_params=Form('{}', description='JSON string of custom parameters for splitting (must be a JSON object).'), chunk_path=Form('data/output', description='Path where the output chunks will be stored.'), download_zip=Form(False, description='If true, returns the chunks in a ZIP archive instead of JSON.'))</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Splits a document into chunks and returns the results.</p> <p>Returns:</p> Type Description <code>Union[ChunkResponse, StreamingResponse]</code> <p>Union[ChunkResponse, StreamingResponse]: A JSON response or ZIP archive with chunks.</p> Source code in <code>src/application/api/routers/split.py</code> <pre><code>@staticmethod\n@router.post(\n    \"/split\",\n    response_model=ChunkResponse,\n    summary=\"Split Document\",\n    description=(\n        \"Splits a document into chunks using the specified split method. \"\n        \"You can either upload a file or specify a file path. \"\n        \"It has an OCR feature to analyze images from the documents. \"\n        \"Optionally, the result can be returned as a ZIP file.\"\n    ),\n)\nasync def split_document(\n    file: Optional[Union[UploadFile, str]] = File(\n        None, description=\"Uploaded file. Leave empty if using a file path.\"\n    ),\n    document_path: str = Form(\n        \"data/input\",\n        description=\"Absolute or relative path where the document is located.\",\n    ),\n    document_name: str = Form(\n        \"\",\n        description=\"Name for the document; if empty, the uploaded file's name is used.\",\n    ),\n    document_id: str = Form(\n        \"\",\n        description=\"Optional document identifier. If empty, one will be generated.\",\n    ),\n    split_method: SplitMethodEnum = Form(\n        ..., description=\"Method to split the document text.\"\n    ),\n    ocr_method: OCRMethodEnum = Form(\n        ...,\n        description=\"OCR client to use for image processing: 'none', 'openai', or 'azure'.\",\n    ),\n    metadata: Optional[List[str]] = Form([], description=\"Optional metadata tags.\"),\n    split_params: str = Form(\n        \"{}\",\n        description=\"JSON string of custom parameters for splitting (must be a JSON object).\",\n    ),\n    chunk_path: str = Form(\n        \"data/output\", description=\"Path where the output chunks will be stored.\"\n    ),\n    download_zip: bool = Form(\n        False,\n        description=\"If true, returns the chunks in a ZIP archive instead of JSON.\",\n    ),\n) -&gt; Union[ChunkResponse, StreamingResponse]:\n    \"\"\"\n    Splits a document into chunks and returns the results.\n\n    Returns:\n        Union[ChunkResponse, StreamingResponse]: A JSON response or ZIP archive with chunks.\n    \"\"\"\n    try:\n        # Normalize paths.\n        document_path = os.path.abspath(document_path)\n        chunk_path = os.path.abspath(chunk_path)\n\n        if isinstance(file, str) and not file.strip():\n            file = None\n\n        # Create unique identifiers.\n        now = datetime.datetime.now()\n        date_str = now.strftime(\"%Y%m%d\")\n        time_str = now.strftime(\"%H%M%S\")\n        uuid_str = uuid.uuid4().hex[:16]\n\n        # Determine file name and directory.\n        if file is not None:\n            file_name = document_name.strip() or file.filename\n            file_dir = document_path\n        else:\n            if not os.path.exists(document_path):\n                raise HTTPException(\n                    status_code=400,\n                    detail=\"No file provided and document_path does not exist.\",\n                )\n            file_name = document_name.strip() or os.path.basename(document_path)\n            file_dir = os.path.dirname(document_path)\n\n        # Generate document_id if not provided.\n        if not document_id.strip():\n            document_id = f\"{uuid_str}_{date_str}_{time_str}_{file_name}\"\n\n        os.makedirs(chunk_path, exist_ok=True)\n\n        # Parse custom split parameters.\n        try:\n            custom_split_params = json.loads(split_params)\n            if not isinstance(custom_split_params, dict):\n                raise ValueError(\"split_params must be a JSON object\")\n            if not custom_split_params:\n                custom_split_params = None\n        except Exception as e:\n            raise HTTPException(\n                status_code=400, detail=f\"Invalid split_params: {e}\"\n            )\n\n        base_config = {\"splitter\": {\"method\": split_method.value}}\n        if custom_split_params:\n            base_config[\"splitter\"][\"methods\"] = {\n                split_method.value: custom_split_params\n            }\n\n        # Prepare ReadManager configuration.\n        read_config = {\n            \"file_io\": {\"input_path\": file_dir},\n            \"ocr\": {\"method\": ocr_method.value},\n        }\n\n        # Instantiate managers.\n        read_manager = ReadManager(config=read_config)\n        split_manager = SplitManager(config=base_config)\n        chunk_manager = ChunkManager(\n            input_path=file_dir,\n            output_path=chunk_path,\n            split_method=split_method.value,\n        )\n\n        # Read document content.\n        markdown_text = (\n            read_manager.read_file_object(file)\n            if file is not None\n            else read_manager.read_file(file_name)\n        )\n\n        chunks = split_manager.split_text(markdown_text)\n        if not chunks:\n            raise HTTPException(\n                status_code=400, detail=\"No chunks generated from the document.\"\n            )\n\n        chunk_manager.save_chunks(\n            chunks, file_name, os.path.splitext(file_name)[1], split_method.value\n        )\n\n        chunk_ids = [\n            f\"{file_name}_{date_str}_{time_str}_chunk_{i}\"\n            for i in range(1, len(chunks) + 1)\n        ]\n\n        if download_zip:\n            zip_io = io.BytesIO()\n            with zipfile.ZipFile(\n                zip_io, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n            ) as zip_file:\n                for i, chunk in enumerate(chunks, start=1):\n                    chunk_filename = (\n                        f\"{os.path.splitext(file_name)[0]}_chunk_{i}.txt\"\n                    )\n                    zip_file.writestr(chunk_filename, chunk)\n            zip_io.seek(0)\n            headers = {\n                \"Content-Disposition\": f\"attachment; filename={os.path.splitext(file_name)[0]}_chunks.zip\"  # noqa: E501, E261\n            }\n            return StreamingResponse(\n                zip_io, media_type=\"application/zip\", headers=headers\n            )\n\n        return ChunkResponse(\n            chunks=chunks,\n            chunk_id=chunk_ids,\n            chunk_path=chunk_path,\n            document_id=document_id,\n            document_name=file_name,\n            split_method=split_method.value,\n            metadata=metadata,\n            split_params=custom_split_params,\n            ocr_method=ocr_method,\n        )\n\n    except HTTPException as http_exc:\n        print(\"HTTPException encountered:\", http_exc.detail)\n        raise http_exc\n    except Exception as e:\n        print(\"Unhandled error encountered:\", e)\n        raise HTTPException(status_code=400, detail=f\"Unhandled error: {e}\")\n</code></pre>"},{"location":"api/docs/#health-check-endpoint","title":"Health Check Endpoint","text":"<p>A class to encapsulate health check endpoints.</p> <p>Use the static method <code>health_check</code> to verify that the service is running.</p> Source code in <code>src/application/api/routers/health.py</code> <pre><code>class HealthAPI:\n    \"\"\"\n    A class to encapsulate health check endpoints.\n\n    Use the static method `health_check` to verify that the service is running.\n    \"\"\"\n\n    @staticmethod\n    @router.get(\"/health-check\", tags=[\"Health\"])\n    async def health_check():\n        \"\"\"\n        Health check endpoint.\n\n        Returns:\n            dict: A JSON response with the application status and the current UTC time.\n        \"\"\"\n        return {\"status\": \"ok\", \"timestamp\": datetime.datetime.utcnow().isoformat()}\n</code></pre> <p>members: false</p>"},{"location":"api/docs/#src.application.api.routers.health.HealthAPI.health_check","title":"<code>health_check()</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Health check endpoint.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A JSON response with the application status and the current UTC time.</p> Source code in <code>src/application/api/routers/health.py</code> <pre><code>@staticmethod\n@router.get(\"/health-check\", tags=[\"Health\"])\nasync def health_check():\n    \"\"\"\n    Health check endpoint.\n\n    Returns:\n        dict: A JSON response with the application status and the current UTC time.\n    \"\"\"\n    return {\"status\": \"ok\", \"timestamp\": datetime.datetime.utcnow().isoformat()}\n</code></pre>"},{"location":"chunker/docs/","title":"Chunking module","text":""},{"location":"chunker/docs/#chunk-manager","title":"Chunk Manager","text":""},{"location":"chunker/docs/#src.chunker.chunk_manager.ChunkManager","title":"<code>ChunkManager</code>","text":"<p>ChunkManager handles the storage and management of text chunks generated by the SplitManager.</p> <p>It is responsible for tasks such as saving chunks to an output directory, aggregating related chunks, and optionally converting them into Markdown format.</p> <p>Attributes:</p> Name Type Description <code>input_path</code> <code>str</code> <p>Directory where the original files are located.</p> <code>output_path</code> <code>str</code> <p>Directory where the resulting chunks will be saved.</p> <code>split_method</code> <code>str</code> <p>The method used for splitting the text.</p> <p>Methods:</p> Name Description <code>save_chunks</code> <p>List[str], file_name: str, extension: str, split_method: str) -&gt; None: Saves each chunk to the output directory, naming them based on the original file name and chunk index.</p> Source code in <code>src/chunker/chunk_manager.py</code> <pre><code>class ChunkManager:\n    \"\"\"\n    ChunkManager handles the storage and management of text chunks generated by the SplitManager.\n\n    It is responsible for tasks such as saving chunks to an output directory, aggregating related\n    chunks, and optionally converting them into Markdown format.\n\n    Attributes:\n        input_path (str): Directory where the original files are located.\n        output_path (str): Directory where the resulting chunks will be saved.\n        split_method (str): The method used for splitting the text.\n\n    Methods:\n        save_chunks(chunks: List[str], file_name: str, extension: str, split_method: str) -&gt; None:\n            Saves each chunk to the output directory, naming them based on the original file name\n            and chunk index.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: Optional[Dict] = None,\n        *,\n        input_path: Optional[str] = None,\n        output_path: Optional[str] = None,\n        split_method: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the ChunkManager with a configuration dictionary or with provided arguments.\n\n        If no configuration dictionary is provided, it builds one using the provided arguments.\n        The output_path defaults to \"&lt;input_path&gt;/output\" if not explicitly provided.\n\n        Args:\n            config (Optional[dict]): A dictionary containing configuration settings.\n            input_path (Optional[str]): The directory path where input files are stored.\n            output_path (Optional[str]): The directory path where the chunk files will be saved.\n            split_method (Optional[str]): The method used for splitting the text.\n        \"\"\"\n        if config is None:\n            # Use defaults if not provided.\n            if input_path is None:\n                input_path = \"data/input\"\n            if output_path is None:\n                output_path = os.path.join(input_path, \"output\")\n            if split_method is None:\n                split_method = \"auto\"\n            config = {\n                \"file_io\": {\n                    \"input_path\": input_path,\n                    \"output_path\": output_path,\n                },\n                \"splitter\": {\"method\": split_method},\n            }\n        self.config = config\n        self.output_path = self.config.get(\"file_io\", {}).get(\n            \"output_path\", \"data/output\"\n        )\n        os.makedirs(self.output_path, exist_ok=True)\n        # Initialize the SplitManager with the provided configuration.\n        self.split_manager = SplitManager(config=self.config)\n\n    def save_chunks(\n        self,\n        chunks: List[str],\n        base_filename: str,\n        original_extension: str,\n        splitter_method: str,\n    ) -&gt; List[str]:\n        \"\"\"\n        Saves the given text chunks into markdown files in a uniquely named directory.\n\n        The directory is created based on the base filename, original file extension,\n        current date and time, and the splitter method used. Each chunk is saved in a separate\n        markdown file following the naming convention:\n        `{base_filename}_{original_extension}_{date}_{time}_chunk_{i}.md`.\n\n        Args:\n            chunks (List[str]): A list of text chunks to be saved.\n            base_filename (str): The base name of the original file used to construct output\n                filenames.\n            original_extension (str): The file extension of the original file (e.g., \".md\").\n            splitter_method (str): The method used for splitting the text (e.g., \"fixed\").\n\n        Returns:\n            List[str]: A list of file paths where the chunks have been saved.\n        \"\"\"\n        now = datetime.datetime.now()\n        date_str = now.strftime(\"%Y%m%d\")\n        time_str = now.strftime(\"%H%M%S\")\n        folder_name = f\"{base_filename}_{original_extension.strip('.')}_{date_str}_{time_str}_{splitter_method}\"  # noqa: E501\n        folder_path = os.path.join(self.output_path, folder_name)\n        os.makedirs(folder_path, exist_ok=True)\n\n        saved_files = []\n        for i, chunk in enumerate(chunks, start=1):\n            chunk_filename = f\"{base_filename}_chunk_{i}.md\"\n            filepath = os.path.join(folder_path, chunk_filename)\n            try:\n                with open(filepath, \"w\", encoding=\"utf-8\") as f:\n                    f.write(chunk)\n                saved_files.append(filepath)\n                logging.info(f\"Chunk {i} saved to {filepath}\")\n            except Exception as e:\n                logging.error(f\"Error saving chunk {i} to {filepath}: {e}\")\n        return saved_files\n</code></pre>"},{"location":"chunker/docs/#src.chunker.chunk_manager.ChunkManager.__init__","title":"<code>__init__(config=None, *, input_path=None, output_path=None, split_method=None)</code>","text":"<p>Initializes the ChunkManager with a configuration dictionary or with provided arguments.</p> <p>If no configuration dictionary is provided, it builds one using the provided arguments. The output_path defaults to \"/output\" if not explicitly provided. <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[dict]</code> <p>A dictionary containing configuration settings.</p> <code>None</code> <code>input_path</code> <code>Optional[str]</code> <p>The directory path where input files are stored.</p> <code>None</code> <code>output_path</code> <code>Optional[str]</code> <p>The directory path where the chunk files will be saved.</p> <code>None</code> <code>split_method</code> <code>Optional[str]</code> <p>The method used for splitting the text.</p> <code>None</code> Source code in <code>src/chunker/chunk_manager.py</code> <pre><code>def __init__(\n    self,\n    config: Optional[Dict] = None,\n    *,\n    input_path: Optional[str] = None,\n    output_path: Optional[str] = None,\n    split_method: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Initializes the ChunkManager with a configuration dictionary or with provided arguments.\n\n    If no configuration dictionary is provided, it builds one using the provided arguments.\n    The output_path defaults to \"&lt;input_path&gt;/output\" if not explicitly provided.\n\n    Args:\n        config (Optional[dict]): A dictionary containing configuration settings.\n        input_path (Optional[str]): The directory path where input files are stored.\n        output_path (Optional[str]): The directory path where the chunk files will be saved.\n        split_method (Optional[str]): The method used for splitting the text.\n    \"\"\"\n    if config is None:\n        # Use defaults if not provided.\n        if input_path is None:\n            input_path = \"data/input\"\n        if output_path is None:\n            output_path = os.path.join(input_path, \"output\")\n        if split_method is None:\n            split_method = \"auto\"\n        config = {\n            \"file_io\": {\n                \"input_path\": input_path,\n                \"output_path\": output_path,\n            },\n            \"splitter\": {\"method\": split_method},\n        }\n    self.config = config\n    self.output_path = self.config.get(\"file_io\", {}).get(\n        \"output_path\", \"data/output\"\n    )\n    os.makedirs(self.output_path, exist_ok=True)\n    # Initialize the SplitManager with the provided configuration.\n    self.split_manager = SplitManager(config=self.config)\n</code></pre> <p>members: false</p>"},{"location":"chunker/docs/#src.chunker.chunk_manager.ChunkManager.save_chunks","title":"<code>save_chunks(chunks, base_filename, original_extension, splitter_method)</code>","text":"<p>Saves the given text chunks into markdown files in a uniquely named directory.</p> <p>The directory is created based on the base filename, original file extension, current date and time, and the splitter method used. Each chunk is saved in a separate markdown file following the naming convention: <code>{base_filename}_{original_extension}_{date}_{time}_chunk_{i}.md</code>.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>List[str]</code> <p>A list of text chunks to be saved.</p> required <code>base_filename</code> <code>str</code> <p>The base name of the original file used to construct output filenames.</p> required <code>original_extension</code> <code>str</code> <p>The file extension of the original file (e.g., \".md\").</p> required <code>splitter_method</code> <code>str</code> <p>The method used for splitting the text (e.g., \"fixed\").</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of file paths where the chunks have been saved.</p> Source code in <code>src/chunker/chunk_manager.py</code> <pre><code>def save_chunks(\n    self,\n    chunks: List[str],\n    base_filename: str,\n    original_extension: str,\n    splitter_method: str,\n) -&gt; List[str]:\n    \"\"\"\n    Saves the given text chunks into markdown files in a uniquely named directory.\n\n    The directory is created based on the base filename, original file extension,\n    current date and time, and the splitter method used. Each chunk is saved in a separate\n    markdown file following the naming convention:\n    `{base_filename}_{original_extension}_{date}_{time}_chunk_{i}.md`.\n\n    Args:\n        chunks (List[str]): A list of text chunks to be saved.\n        base_filename (str): The base name of the original file used to construct output\n            filenames.\n        original_extension (str): The file extension of the original file (e.g., \".md\").\n        splitter_method (str): The method used for splitting the text (e.g., \"fixed\").\n\n    Returns:\n        List[str]: A list of file paths where the chunks have been saved.\n    \"\"\"\n    now = datetime.datetime.now()\n    date_str = now.strftime(\"%Y%m%d\")\n    time_str = now.strftime(\"%H%M%S\")\n    folder_name = f\"{base_filename}_{original_extension.strip('.')}_{date_str}_{time_str}_{splitter_method}\"  # noqa: E501\n    folder_path = os.path.join(self.output_path, folder_name)\n    os.makedirs(folder_path, exist_ok=True)\n\n    saved_files = []\n    for i, chunk in enumerate(chunks, start=1):\n        chunk_filename = f\"{base_filename}_chunk_{i}.md\"\n        filepath = os.path.join(folder_path, chunk_filename)\n        try:\n            with open(filepath, \"w\", encoding=\"utf-8\") as f:\n                f.write(chunk)\n            saved_files.append(filepath)\n            logging.info(f\"Chunk {i} saved to {filepath}\")\n        except Exception as e:\n            logging.error(f\"Error saving chunk {i} to {filepath}: {e}\")\n    return saved_files\n</code></pre>"},{"location":"model/docs/","title":"Models documentation","text":""},{"location":"model/docs/#llm-client","title":"LLM Client","text":""},{"location":"model/docs/#src.model.llm_client.LLMClient","title":"<code>LLMClient</code>","text":"<p>LLMClient is a factory and wrapper class for initializing and managing large language model (LLM) or OCR clients based on a given configuration.</p> <p>Depending on the specified method, this class instantiates one of the following:</p> <ul> <li>openai: Uses <code>OpenAIClient</code> to interface with OpenAI's API.</li> <li>azure: Uses <code>AzureOpenAIClient</code> to interface with Azure OpenAI service.</li> <li>none: Disables client functionality (no LLM client is instantiated).</li> </ul> The class provides helper methods to <ul> <li>Retrieve the underlying client instance.</li> <li>Get the model name associated with the client.</li> <li>Check if a valid client is enabled.</li> </ul> Source code in <code>src/model/llm_client.py</code> <pre><code>class LLMClient:\n    \"\"\"\n    LLMClient is a factory and wrapper class for initializing and managing large language model (LLM)\n    or OCR clients based on a given configuration.\n\n    Depending on the specified method, this class instantiates one of the following:\n\n      - **openai**: Uses `OpenAIClient` to interface with OpenAI's API.\n      - **azure**: Uses `AzureOpenAIClient` to interface with Azure OpenAI service.\n      - **none**: Disables client functionality (no LLM client is instantiated).\n\n    The class provides helper methods to:\n      - Retrieve the underlying client instance.\n      - Get the model name associated with the client.\n      - Check if a valid client is enabled.\n    \"\"\"\n\n    def __init__(self, method: str):\n        \"\"\"\n        Initializes the LLMClient based on the specified method.\n\n        Args:\n            method (str): Specifies the client type. Must be one of:\n                - \"openai\" to use OpenAIClient.\n                - \"azure\" to use AzureOpenAIClient.\n                - \"none\" for no client.\n\n        Raises:\n            ValueError: If an unsupported method is provided.\n        \"\"\"\n        self.method = method.lower()\n        if self.method == \"openai\":\n            self.client_instance: Optional[BaseLLMClient] = OpenAIClient()\n        elif self.method == \"azure\":\n            self.client_instance: Optional[BaseLLMClient] = AzureOpenAIClient()\n        elif self.method == \"none\":\n            self.client_instance = None\n        else:\n            raise ValueError(\n                f\"Unsupported LLM method: '{self.method}'. Only 'openai', 'azure', or 'none' are allowed.\"  # noqa: E501\n            )\n\n    def get_client(self) -&gt; Optional[object]:\n        \"\"\"\n        Retrieves the underlying LLM client instance.\n\n        Returns:\n            Optional[object]: The client instance if available; otherwise, None.\n        \"\"\"\n        if self.client_instance is None:\n            return None\n        return self.client_instance.get_client()\n\n    def get_model(self) -&gt; Optional[str]:\n        \"\"\"\n        Retrieves the model name used by the LLM client.\n\n        Returns:\n            Optional[str]: The model name if the client is enabled; otherwise, None.\n        \"\"\"\n        if self.client_instance is None:\n            return None\n        return self.client_instance.get_model()\n\n    def is_enabled(self) -&gt; bool:\n        \"\"\"\n        Checks if a valid LLM client is enabled.\n\n        Returns:\n            bool: True if a client is instantiated and enabled; otherwise, False.\n        \"\"\"\n        return self.client_instance is not None and self.client_instance.is_enabled()\n</code></pre>"},{"location":"model/docs/#src.model.llm_client.LLMClient.__init__","title":"<code>__init__(method)</code>","text":"<p>Initializes the LLMClient based on the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Specifies the client type. Must be one of: - \"openai\" to use OpenAIClient. - \"azure\" to use AzureOpenAIClient. - \"none\" for no client.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported method is provided.</p> Source code in <code>src/model/llm_client.py</code> <pre><code>def __init__(self, method: str):\n    \"\"\"\n    Initializes the LLMClient based on the specified method.\n\n    Args:\n        method (str): Specifies the client type. Must be one of:\n            - \"openai\" to use OpenAIClient.\n            - \"azure\" to use AzureOpenAIClient.\n            - \"none\" for no client.\n\n    Raises:\n        ValueError: If an unsupported method is provided.\n    \"\"\"\n    self.method = method.lower()\n    if self.method == \"openai\":\n        self.client_instance: Optional[BaseLLMClient] = OpenAIClient()\n    elif self.method == \"azure\":\n        self.client_instance: Optional[BaseLLMClient] = AzureOpenAIClient()\n    elif self.method == \"none\":\n        self.client_instance = None\n    else:\n        raise ValueError(\n            f\"Unsupported LLM method: '{self.method}'. Only 'openai', 'azure', or 'none' are allowed.\"  # noqa: E501\n        )\n</code></pre>"},{"location":"model/docs/#src.model.llm_client.LLMClient.get_client","title":"<code>get_client()</code>","text":"<p>Retrieves the underlying LLM client instance.</p> <p>Returns:</p> Type Description <code>Optional[object]</code> <p>Optional[object]: The client instance if available; otherwise, None.</p> Source code in <code>src/model/llm_client.py</code> <pre><code>def get_client(self) -&gt; Optional[object]:\n    \"\"\"\n    Retrieves the underlying LLM client instance.\n\n    Returns:\n        Optional[object]: The client instance if available; otherwise, None.\n    \"\"\"\n    if self.client_instance is None:\n        return None\n    return self.client_instance.get_client()\n</code></pre>"},{"location":"model/docs/#src.model.llm_client.LLMClient.get_model","title":"<code>get_model()</code>","text":"<p>Retrieves the model name used by the LLM client.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Optional[str]: The model name if the client is enabled; otherwise, None.</p> Source code in <code>src/model/llm_client.py</code> <pre><code>def get_model(self) -&gt; Optional[str]:\n    \"\"\"\n    Retrieves the model name used by the LLM client.\n\n    Returns:\n        Optional[str]: The model name if the client is enabled; otherwise, None.\n    \"\"\"\n    if self.client_instance is None:\n        return None\n    return self.client_instance.get_model()\n</code></pre>"},{"location":"model/docs/#src.model.llm_client.LLMClient.is_enabled","title":"<code>is_enabled()</code>","text":"<p>Checks if a valid LLM client is enabled.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if a client is instantiated and enabled; otherwise, False.</p> Source code in <code>src/model/llm_client.py</code> <pre><code>def is_enabled(self) -&gt; bool:\n    \"\"\"\n    Checks if a valid LLM client is enabled.\n\n    Returns:\n        bool: True if a client is instantiated and enabled; otherwise, False.\n    \"\"\"\n    return self.client_instance is not None and self.client_instance.is_enabled()\n</code></pre>"},{"location":"model/docs/#base-client","title":"Base Client","text":""},{"location":"model/docs/#src.model.base_client.BaseLLMClient","title":"<code>BaseLLMClient</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for LLM clients.</p> Source code in <code>src/model/base_client.py</code> <pre><code>class BaseLLMClient(ABC):\n    \"\"\"\n    Abstract base class for LLM clients.\n    \"\"\"\n\n    @abstractmethod\n    def get_client(self) -&gt; object:\n        \"\"\"\n        Returns the underlying LLM client instance.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_model(self) -&gt; Optional[str]:\n        \"\"\"\n        Returns the model name if applicable.\n        \"\"\"\n        pass\n\n    def is_enabled(self) -&gt; bool:\n        \"\"\"\n        Returns True if the client is active.\n        \"\"\"\n        return self.get_client() is not None\n</code></pre>"},{"location":"model/docs/#src.model.base_client.BaseLLMClient.get_client","title":"<code>get_client()</code>  <code>abstractmethod</code>","text":"<p>Returns the underlying LLM client instance.</p> Source code in <code>src/model/base_client.py</code> <pre><code>@abstractmethod\ndef get_client(self) -&gt; object:\n    \"\"\"\n    Returns the underlying LLM client instance.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"model/docs/#src.model.base_client.BaseLLMClient.get_model","title":"<code>get_model()</code>  <code>abstractmethod</code>","text":"<p>Returns the model name if applicable.</p> Source code in <code>src/model/base_client.py</code> <pre><code>@abstractmethod\ndef get_model(self) -&gt; Optional[str]:\n    \"\"\"\n    Returns the model name if applicable.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"model/docs/#src.model.base_client.BaseLLMClient.is_enabled","title":"<code>is_enabled()</code>","text":"<p>Returns True if the client is active.</p> Source code in <code>src/model/base_client.py</code> <pre><code>def is_enabled(self) -&gt; bool:\n    \"\"\"\n    Returns True if the client is active.\n    \"\"\"\n    return self.get_client() is not None\n</code></pre>"},{"location":"model/docs/#available-clients","title":"Available Clients","text":""},{"location":"model/docs/#src.model.models.azure_client.AzureOpenAIClient","title":"<code>AzureOpenAIClient</code>","text":"<p>               Bases: <code>BaseLLMClient</code></p> <p>Client for interacting with Azure OpenAI.</p> Source code in <code>src/model/models/azure_client.py</code> <pre><code>class AzureOpenAIClient(BaseLLMClient):\n    \"\"\"\n    Client for interacting with Azure OpenAI.\n    \"\"\"\n\n    def __init__(self):\n        self.client = openai.AzureOpenAI(\n            api_key=settings.azure_openai_api_key,\n            api_version=settings.azure_openai_api_version,\n            azure_endpoint=settings.azure_openai_endpoint,\n        )\n        self.model = settings.azure_openai_deployment\n\n    def get_client(self) -&gt; object:\n        return self.client\n\n    def get_model(self) -&gt; str:\n        return self.model\n</code></pre>"},{"location":"model/docs/#src.model.models.openai_client.OpenAIClient","title":"<code>OpenAIClient</code>","text":"<p>               Bases: <code>BaseLLMClient</code></p> <p>Client for interacting with OpenAI.</p> Source code in <code>src/model/models/openai_client.py</code> <pre><code>class OpenAIClient(BaseLLMClient):\n    \"\"\"\n    Client for interacting with OpenAI.\n    \"\"\"\n\n    def __init__(self):\n        self.client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n        self.model = os.environ.get(\"OPENAI_MODEL\")\n\n    def get_client(self) -&gt; object:\n        return self.client\n\n    def get_model(self) -&gt; Optional[str]:\n        return self.model\n</code></pre>"},{"location":"reader/docs/","title":"Reader module","text":""},{"location":"reader/docs/#read-manager","title":"Read Manager","text":"<p>members: false</p>"},{"location":"reader/docs/#src.reader.read_manager.ReadManager","title":"<code>ReadManager</code>","text":"<p>ReadManager is responsible for reading input documents from a specified location.</p> <p>This class supports multiple file formats such as text files (.txt, .md), Microsoft  Word (.docx), PDFs, PowerPoint files (.pptx), and Excel files (.xlsx). It can also  apply OCR processing when required.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>dict</code> <p>Configuration settings for file I/O, including input path and OCR method.</p> <p>Methods:</p> Name Description <code>read_file</code> <p>str) -&gt; str: Reads the file from the given path and returns its content as a string.</p> <code>read_file_object</code> <p>UploadFile) -&gt; str: Reads the content from an uploaded file object and returns it as a string.</p> Source code in <code>src/reader/read_manager.py</code> <pre><code>class ReadManager:\n    \"\"\"\n    ReadManager is responsible for reading input documents from a specified location.\n\n    This class supports multiple file formats such as text files (.txt, .md), Microsoft \n    Word (.docx), PDFs, PowerPoint files (.pptx), and Excel files (.xlsx). It can also \n    apply OCR processing when required.\n\n    Attributes:\n        config (dict): Configuration settings for file I/O, including input path and OCR method.\n\n    Methods:\n        read_file(file_path: str) -&gt; str:\n            Reads the file from the given path and returns its content as a string.\n        read_file_object(file: UploadFile) -&gt; str:\n            Reads the content from an uploaded file object and returns it as a string.\n    \"\"\"\n\n    def __init__(\n        self, config: Optional[Dict] = None, *, input_path: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Initializes ReadManager with a configuration or a default input path.\n\n        Args:\n            config (dict, optional): Configuration dictionary.\n            input_path (str, optional): Path to the input directory.\n        \"\"\"\n        if config is None:\n            input_path = input_path or \"data/input\"\n            config = {\"file_io\": {\"input_path\": input_path}}\n        self.config: Dict = config\n        self.input_path: str = self.config.get(\"file_io\", {}).get(\n            \"input_path\", \"data/input\"\n        )\n        self.llm: LLMClient = LLMClient(\n            self.config.get(\"ocr\", {}).get(\"method\", \"none\")\n        )\n\n    def read_file(self, file_path: str) -&gt; str:\n        \"\"\"\n        Reads and converts a file from the given file path to Markdown text.\n\n        Args:\n            file_path (str): Path to the file.\n\n        Returns:\n            str: Converted Markdown text.\n        \"\"\"\n        if not os.path.isabs(file_path):\n            file_path = os.path.join(self.input_path, file_path)\n\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"File not found: {file_path}\")\n        if os.path.getsize(file_path) == 0:\n            raise ValueError(\"File is empty\")\n\n        ext = file_path.lower().split(\".\")[-1]\n        converter = self._get_converter_for_extension(ext)\n        if converter is None:\n            raise ValueError(\"Unsupported file extension\")\n\n        try:\n            return converter.convert(file_path)\n        except Exception as e:\n            logging.error(\n                f\"Error converting file {file_path} using {converter.__class__.__name__}: {e}\"\n            )\n            raise RuntimeError(\"Failed to convert file\")\n\n    def read_file_object(self, file: UploadFile) -&gt; str:\n        \"\"\"\n        Reads and converts an uploaded file object to Markdown text.\n        The file is temporarily saved to disk, processed, and then deleted.\n\n        Args:\n            file (UploadFile): The uploaded file object.\n\n        Returns:\n            str: Converted Markdown text.\n        \"\"\"\n        tmp_path = \"\"\n        try:\n            with tempfile.NamedTemporaryFile(\n                delete=False, suffix=\".\" + file.filename.split(\".\")[-1]\n            ) as tmp:\n                tmp.write(file.file.read())\n                tmp_path = tmp.name\n            return self.read_file(tmp_path)\n        finally:\n            if tmp_path and os.path.exists(tmp_path):\n                os.remove(tmp_path)\n\n    def _get_converter_for_extension(self, ext: str) -&gt; Optional[MarkItDownConverter]:\n        \"\"\"\n        Returns the appropriate converter based on file extension.\n\n        Args:\n            ext (str): File extension.\n\n        Returns:\n            Optional[MarkItDownConverter]: Converter instance or None if unsupported.\n        \"\"\"\n        client = self.llm.get_client()\n        model = self.llm.get_model()\n\n        mapping: Dict[str, MarkItDownConverter] = {\n            \"txt\": MarkItDownConverter(client, model),\n            \"md\": MarkItDownConverter(client, model),\n            \"docx\": MarkItDownConverter(client, model),\n            \"xlsx\": MarkItDownConverter(client, model),\n            \"pptx\": MarkItDownConverter(client, model),\n            \"pdf\": MarkItDownConverter(client, model),\n            \"jpg\": MarkItDownConverter(client, model),\n            \"jpeg\": MarkItDownConverter(client, model),\n            \"png\": MarkItDownConverter(client, model),\n        }\n        return mapping.get(ext)\n</code></pre>"},{"location":"reader/docs/#src.reader.read_manager.ReadManager.__init__","title":"<code>__init__(config=None, *, input_path=None)</code>","text":"<p>Initializes ReadManager with a configuration or a default input path.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary.</p> <code>None</code> <code>input_path</code> <code>str</code> <p>Path to the input directory.</p> <code>None</code> Source code in <code>src/reader/read_manager.py</code> <pre><code>def __init__(\n    self, config: Optional[Dict] = None, *, input_path: Optional[str] = None\n) -&gt; None:\n    \"\"\"\n    Initializes ReadManager with a configuration or a default input path.\n\n    Args:\n        config (dict, optional): Configuration dictionary.\n        input_path (str, optional): Path to the input directory.\n    \"\"\"\n    if config is None:\n        input_path = input_path or \"data/input\"\n        config = {\"file_io\": {\"input_path\": input_path}}\n    self.config: Dict = config\n    self.input_path: str = self.config.get(\"file_io\", {}).get(\n        \"input_path\", \"data/input\"\n    )\n    self.llm: LLMClient = LLMClient(\n        self.config.get(\"ocr\", {}).get(\"method\", \"none\")\n    )\n</code></pre>"},{"location":"reader/docs/#src.reader.read_manager.ReadManager._get_converter_for_extension","title":"<code>_get_converter_for_extension(ext)</code>","text":"<p>Returns the appropriate converter based on file extension.</p> <p>Parameters:</p> Name Type Description Default <code>ext</code> <code>str</code> <p>File extension.</p> required <p>Returns:</p> Type Description <code>Optional[MarkItDownConverter]</code> <p>Optional[MarkItDownConverter]: Converter instance or None if unsupported.</p> Source code in <code>src/reader/read_manager.py</code> <pre><code>def _get_converter_for_extension(self, ext: str) -&gt; Optional[MarkItDownConverter]:\n    \"\"\"\n    Returns the appropriate converter based on file extension.\n\n    Args:\n        ext (str): File extension.\n\n    Returns:\n        Optional[MarkItDownConverter]: Converter instance or None if unsupported.\n    \"\"\"\n    client = self.llm.get_client()\n    model = self.llm.get_model()\n\n    mapping: Dict[str, MarkItDownConverter] = {\n        \"txt\": MarkItDownConverter(client, model),\n        \"md\": MarkItDownConverter(client, model),\n        \"docx\": MarkItDownConverter(client, model),\n        \"xlsx\": MarkItDownConverter(client, model),\n        \"pptx\": MarkItDownConverter(client, model),\n        \"pdf\": MarkItDownConverter(client, model),\n        \"jpg\": MarkItDownConverter(client, model),\n        \"jpeg\": MarkItDownConverter(client, model),\n        \"png\": MarkItDownConverter(client, model),\n    }\n    return mapping.get(ext)\n</code></pre>"},{"location":"reader/docs/#src.reader.read_manager.ReadManager.read_file","title":"<code>read_file(file_path)</code>","text":"<p>Reads and converts a file from the given file path to Markdown text.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Converted Markdown text.</p> Source code in <code>src/reader/read_manager.py</code> <pre><code>def read_file(self, file_path: str) -&gt; str:\n    \"\"\"\n    Reads and converts a file from the given file path to Markdown text.\n\n    Args:\n        file_path (str): Path to the file.\n\n    Returns:\n        str: Converted Markdown text.\n    \"\"\"\n    if not os.path.isabs(file_path):\n        file_path = os.path.join(self.input_path, file_path)\n\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    if os.path.getsize(file_path) == 0:\n        raise ValueError(\"File is empty\")\n\n    ext = file_path.lower().split(\".\")[-1]\n    converter = self._get_converter_for_extension(ext)\n    if converter is None:\n        raise ValueError(\"Unsupported file extension\")\n\n    try:\n        return converter.convert(file_path)\n    except Exception as e:\n        logging.error(\n            f\"Error converting file {file_path} using {converter.__class__.__name__}: {e}\"\n        )\n        raise RuntimeError(\"Failed to convert file\")\n</code></pre>"},{"location":"reader/docs/#src.reader.read_manager.ReadManager.read_file_object","title":"<code>read_file_object(file)</code>","text":"<p>Reads and converts an uploaded file object to Markdown text. The file is temporarily saved to disk, processed, and then deleted.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>UploadFile</code> <p>The uploaded file object.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Converted Markdown text.</p> Source code in <code>src/reader/read_manager.py</code> <pre><code>def read_file_object(self, file: UploadFile) -&gt; str:\n    \"\"\"\n    Reads and converts an uploaded file object to Markdown text.\n    The file is temporarily saved to disk, processed, and then deleted.\n\n    Args:\n        file (UploadFile): The uploaded file object.\n\n    Returns:\n        str: Converted Markdown text.\n    \"\"\"\n    tmp_path = \"\"\n    try:\n        with tempfile.NamedTemporaryFile(\n            delete=False, suffix=\".\" + file.filename.split(\".\")[-1]\n        ) as tmp:\n            tmp.write(file.file.read())\n            tmp_path = tmp.name\n        return self.read_file(tmp_path)\n    finally:\n        if tmp_path and os.path.exists(tmp_path):\n            os.remove(tmp_path)\n</code></pre>"},{"location":"reader/docs/#base-reader","title":"Base Reader","text":"<p>members: false</p>"},{"location":"reader/docs/#src.reader.base_reader.BaseReader","title":"<code>BaseReader</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class which implements Readers.</p> Source code in <code>src/reader/base_reader.py</code> <pre><code>class BaseReader(ABC):\n    \"\"\"\n    Abstract class which implements Readers.\n    \"\"\"\n\n    @abstractmethod\n    def convert(self, file_path: str) -&gt; str | dict:\n        pass\n</code></pre>"},{"location":"reader/docs/#readers","title":"Readers","text":"<p>members: false</p>"},{"location":"splitter/docs/","title":"Splitter module","text":"<p>members: false</p>"},{"location":"splitter/docs/#src.splitter.split_manager.SplitManager","title":"<code>SplitManager</code>","text":"<p>SplitManager is responsible for splitting text into meaningful chunks based on a  specified strategy.</p> <p>It supports various splitting methods, including word, sentence, paragraph, fixed,  recursive, and others. The splitting behavior is configurable via the provided settings.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>dict</code> <p>Configuration parameters specifying the splitting method and any </p> <p>Methods:</p> Name Description <code>split_text</code> <p>str) -&gt; List[str]: Splits the given text into a list of chunks according to the configured splitting  strategy.</p> Source code in <code>src/splitter/split_manager.py</code> <pre><code>class SplitManager:\n    \"\"\"\n    SplitManager is responsible for splitting text into meaningful chunks based on a \n    specified strategy.\n\n    It supports various splitting methods, including word, sentence, paragraph, fixed, \n    recursive, and others. The splitting behavior is configurable via the provided settings.\n\n    Attributes:\n        config (dict): Configuration parameters specifying the splitting method and any \n        custom parameters.\n\n    Methods:\n        split_text(text: str) -&gt; List[str]:\n            Splits the given text into a list of chunks according to the configured splitting \n            strategy.\n    \"\"\"\n\n    def __init__(\n        self, config: Optional[Dict] = None, *, split_method: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Initializes the SplitManager with a configuration dictionary or with provided \n        arguments.\n\n        If no configuration is provided, a configuration dictionary is built using the \n        provided `split_method`. Defaults to `\"auto\"` if not specified.\n\n        Args:\n            config (Optional[dict]): A dictionary containing configuration settings.\n            split_method (Optional[str]): The method used for splitting the text.\n        \"\"\"\n        if config is None:\n            if split_method is None:\n                split_method = \"auto\"\n            config = {\"splitter\": {\"method\": split_method}}\n        self.config = config\n        self.splitter = self._create_splitter()\n\n    def _create_splitter(self) -&gt; BaseSplitter:\n        \"\"\"\n        Factory method to instantiate the desired splitter from configuration.\n\n        This method loads all parameters for the selected splitting method from the \n        configuration and instantiates the corresponding splitter class.\n\n        Returns:\n            BaseSplitter: An instance of a class that implements the splitter \n            interface.\n\n        Raises:\n            ValueError: If the specified splitting method is not supported.\n        \"\"\"\n        splitter_config = self.config.get(\"splitter\", {})\n        method = splitter_config.get(\"method\", \"auto\")\n\n        splitter_mapping = {\n            \"word\": WordSplitter,\n            \"sentence\": SentenceSplitter,\n            \"paragraph\": ParagraphSplitter,\n            \"fixed\": FixedSplitter,\n            \"recursive\": RecursiveSplitter,\n            # \"semantic\": SemanticSplitter,\n            # \"paged\": PagedSplitter,\n            # \"row-column\": RowColumnSplitter,\n            # \"schema-based\": SchemaBasedSplitter,\n            # \"auto\": AutoSplitter,\n        }\n\n        splitter_class = splitter_mapping.get(method)\n        if not splitter_class:\n            raise ValueError(f\"Invalid splitting method: {method}\")\n\n        # Access the parameters from the nested \"methods\" key in the configuration.\n        params = splitter_config.get(\"methods\", {}).get(method, {})\n        return splitter_class(**params)\n\n    def split_text(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Splits the provided text into smaller chunks using the configured splitter.\n\n        If the text is empty or only contains whitespace, a warning is logged and \n        an empty list is returned. In case of an error during splitting, an error is \n        logged and an empty list is returned.\n\n        Args:\n            text (str): The text to be split.\n\n        Returns:\n            List[str]: A list of text chunks generated by the splitter.\n        \"\"\"\n        if not text.strip():\n            logging.warning(\"Empty text provided for splitting.\")\n            return []\n        try:\n            return self.splitter.split(text)\n        except Exception as e:\n            logging.error(f\"Error during text splitting: {e}\")\n            return []\n</code></pre>"},{"location":"splitter/docs/#src.splitter.split_manager.SplitManager.__init__","title":"<code>__init__(config=None, *, split_method=None)</code>","text":"<p>Initializes the SplitManager with a configuration dictionary or with provided  arguments.</p> <p>If no configuration is provided, a configuration dictionary is built using the  provided <code>split_method</code>. Defaults to <code>\"auto\"</code> if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[dict]</code> <p>A dictionary containing configuration settings.</p> <code>None</code> <code>split_method</code> <code>Optional[str]</code> <p>The method used for splitting the text.</p> <code>None</code> Source code in <code>src/splitter/split_manager.py</code> <pre><code>def __init__(\n    self, config: Optional[Dict] = None, *, split_method: Optional[str] = None\n) -&gt; None:\n    \"\"\"\n    Initializes the SplitManager with a configuration dictionary or with provided \n    arguments.\n\n    If no configuration is provided, a configuration dictionary is built using the \n    provided `split_method`. Defaults to `\"auto\"` if not specified.\n\n    Args:\n        config (Optional[dict]): A dictionary containing configuration settings.\n        split_method (Optional[str]): The method used for splitting the text.\n    \"\"\"\n    if config is None:\n        if split_method is None:\n            split_method = \"auto\"\n        config = {\"splitter\": {\"method\": split_method}}\n    self.config = config\n    self.splitter = self._create_splitter()\n</code></pre>"},{"location":"splitter/docs/#src.splitter.split_manager.SplitManager._create_splitter","title":"<code>_create_splitter()</code>","text":"<p>Factory method to instantiate the desired splitter from configuration.</p> <p>This method loads all parameters for the selected splitting method from the  configuration and instantiates the corresponding splitter class.</p> <p>Returns:</p> Name Type Description <code>BaseSplitter</code> <code>BaseSplitter</code> <p>An instance of a class that implements the splitter </p> <code>BaseSplitter</code> <p>interface.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified splitting method is not supported.</p> Source code in <code>src/splitter/split_manager.py</code> <pre><code>def _create_splitter(self) -&gt; BaseSplitter:\n    \"\"\"\n    Factory method to instantiate the desired splitter from configuration.\n\n    This method loads all parameters for the selected splitting method from the \n    configuration and instantiates the corresponding splitter class.\n\n    Returns:\n        BaseSplitter: An instance of a class that implements the splitter \n        interface.\n\n    Raises:\n        ValueError: If the specified splitting method is not supported.\n    \"\"\"\n    splitter_config = self.config.get(\"splitter\", {})\n    method = splitter_config.get(\"method\", \"auto\")\n\n    splitter_mapping = {\n        \"word\": WordSplitter,\n        \"sentence\": SentenceSplitter,\n        \"paragraph\": ParagraphSplitter,\n        \"fixed\": FixedSplitter,\n        \"recursive\": RecursiveSplitter,\n        # \"semantic\": SemanticSplitter,\n        # \"paged\": PagedSplitter,\n        # \"row-column\": RowColumnSplitter,\n        # \"schema-based\": SchemaBasedSplitter,\n        # \"auto\": AutoSplitter,\n    }\n\n    splitter_class = splitter_mapping.get(method)\n    if not splitter_class:\n        raise ValueError(f\"Invalid splitting method: {method}\")\n\n    # Access the parameters from the nested \"methods\" key in the configuration.\n    params = splitter_config.get(\"methods\", {}).get(method, {})\n    return splitter_class(**params)\n</code></pre>"},{"location":"splitter/docs/#src.splitter.split_manager.SplitManager.split_text","title":"<code>split_text(text)</code>","text":"<p>Splits the provided text into smaller chunks using the configured splitter.</p> <p>If the text is empty or only contains whitespace, a warning is logged and  an empty list is returned. In case of an error during splitting, an error is  logged and an empty list is returned.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to be split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks generated by the splitter.</p> Source code in <code>src/splitter/split_manager.py</code> <pre><code>def split_text(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Splits the provided text into smaller chunks using the configured splitter.\n\n    If the text is empty or only contains whitespace, a warning is logged and \n    an empty list is returned. In case of an error during splitting, an error is \n    logged and an empty list is returned.\n\n    Args:\n        text (str): The text to be split.\n\n    Returns:\n        List[str]: A list of text chunks generated by the splitter.\n    \"\"\"\n    if not text.strip():\n        logging.warning(\"Empty text provided for splitting.\")\n        return []\n    try:\n        return self.splitter.split(text)\n    except Exception as e:\n        logging.error(f\"Error during text splitting: {e}\")\n        return []\n</code></pre>"},{"location":"splitter/docs/#base-splitter","title":"Base Splitter","text":"<p>members: false</p>"},{"location":"splitter/docs/#src.splitter.base_splitter.BaseSplitter","title":"<code>BaseSplitter</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>src/splitter/base_splitter.py</code> <pre><code>class BaseSplitter(ABC):\n    @abstractmethod\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Split the provided text into chunks.\n\n        Args:\n            text (str): The text to split.\n\n        Returns:\n            List[str]: A list of text chunks.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"splitter/docs/#src.splitter.base_splitter.BaseSplitter.split","title":"<code>split(text)</code>  <code>abstractmethod</code>","text":"<p>Split the provided text into chunks.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks.</p> Source code in <code>src/splitter/base_splitter.py</code> <pre><code>@abstractmethod\ndef split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Split the provided text into chunks.\n\n    Args:\n        text (str): The text to split.\n\n    Returns:\n        List[str]: A list of text chunks.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"splitter/docs/#splitting-methods","title":"Splitting Methods","text":"<p>members: false</p> <p>members: false</p> <p>members: false</p> <p>members: false</p> <p>members: false</p>"},{"location":"splitter/docs/#src.splitter.splitters.word_splitter.WordSplitter","title":"<code>WordSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Splits the input text into individual words.</p> <p>This class tokenizes the text into words using whitespace and punctuation as delimiters. It is particularly useful for further processing that requires analysis at the word level.</p> Source code in <code>src/splitter/splitters/word_splitter.py</code> <pre><code>class WordSplitter(BaseSplitter):\n    \"\"\"\n    Splits the input text into individual words.\n\n    This class tokenizes the text into words using whitespace and punctuation as delimiters.\n    It is particularly useful for further processing that requires analysis at the word level.\n    \"\"\"\n\n    def __init__(self, num_words: int = 10) -&gt; None:\n        \"\"\"\n        Initialize the splitter with the number of words per chunk.\n\n        Args:\n            num_words (int): The desired number of words per chunk.\n                             Must be greater than 0.\n        \"\"\"\n        if num_words &lt;= 0:\n            raise ValueError(\"num_words must be greater than 0\")\n        self.num_words = num_words\n\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Split the text into chunks of words.\n\n        Args:\n            text (str): The input text.\n\n        Returns:\n            List[str]: A list of text chunks.\n        \"\"\"\n        words = text.split()\n        groups = []\n        for i in range(0, len(words), self.num_words):\n            group = \" \".join(words[i : i + self.num_words])\n            groups.append(group)\n        return groups\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.word_splitter.WordSplitter.__init__","title":"<code>__init__(num_words=10)</code>","text":"<p>Initialize the splitter with the number of words per chunk.</p> <p>Parameters:</p> Name Type Description Default <code>num_words</code> <code>int</code> <p>The desired number of words per chunk.              Must be greater than 0.</p> <code>10</code> Source code in <code>src/splitter/splitters/word_splitter.py</code> <pre><code>def __init__(self, num_words: int = 10) -&gt; None:\n    \"\"\"\n    Initialize the splitter with the number of words per chunk.\n\n    Args:\n        num_words (int): The desired number of words per chunk.\n                         Must be greater than 0.\n    \"\"\"\n    if num_words &lt;= 0:\n        raise ValueError(\"num_words must be greater than 0\")\n    self.num_words = num_words\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.word_splitter.WordSplitter.split","title":"<code>split(text)</code>","text":"<p>Split the text into chunks of words.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input text.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks.</p> Source code in <code>src/splitter/splitters/word_splitter.py</code> <pre><code>def split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Split the text into chunks of words.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        List[str]: A list of text chunks.\n    \"\"\"\n    words = text.split()\n    groups = []\n    for i in range(0, len(words), self.num_words):\n        group = \" \".join(words[i : i + self.num_words])\n        groups.append(group)\n    return groups\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.sentence_splitter.SentenceSplitter","title":"<code>SentenceSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Splits the input text into sentences.</p> <p>This class breaks the text into sentences by detecting sentence boundaries, typically using punctuation marks such as periods, exclamation points, and question marks. It also attempts to handle common edge cases, such as abbreviations, to improve accuracy.</p> Source code in <code>src/splitter/splitters/sentence_splitter.py</code> <pre><code>class SentenceSplitter(BaseSplitter):\n    \"\"\"\n    Splits the input text into sentences.\n\n    This class breaks the text into sentences by detecting sentence boundaries, typically using\n    punctuation marks such as periods, exclamation points, and question marks. It also attempts to\n    handle common edge cases, such as abbreviations, to improve accuracy.\n    \"\"\"\n\n    def __init__(self, num_sentences: int = 5):\n        \"\"\"\n        Initialize the splitter with the number of sentences per group.\n        :param num_sentences: Number of sentences to group together.\n        \"\"\"\n        if num_sentences &lt;= 0:\n            raise ValueError(\"num_sentences must be greater than 0\")\n        self.num_sentences = num_sentences\n\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Split the markdown text into groups of sentences.\n        :param text: The markdown text to split.\n        :return: A list of sentence groups.\n        \"\"\"\n        sentences = re.split(r\"(?&lt;=[.!?])\\s+\", text)\n        sentences = [s.strip() for s in sentences if s.strip()]\n\n        chunks = []\n        for i in range(0, len(sentences), self.num_sentences):\n            chunk = \" \".join(sentences[i : i + self.num_sentences])\n            chunks.append(chunk)\n        return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.sentence_splitter.SentenceSplitter.__init__","title":"<code>__init__(num_sentences=5)</code>","text":"<p>Initialize the splitter with the number of sentences per group. :param num_sentences: Number of sentences to group together.</p> Source code in <code>src/splitter/splitters/sentence_splitter.py</code> <pre><code>def __init__(self, num_sentences: int = 5):\n    \"\"\"\n    Initialize the splitter with the number of sentences per group.\n    :param num_sentences: Number of sentences to group together.\n    \"\"\"\n    if num_sentences &lt;= 0:\n        raise ValueError(\"num_sentences must be greater than 0\")\n    self.num_sentences = num_sentences\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.sentence_splitter.SentenceSplitter.split","title":"<code>split(text)</code>","text":"<p>Split the markdown text into groups of sentences. :param text: The markdown text to split. :return: A list of sentence groups.</p> Source code in <code>src/splitter/splitters/sentence_splitter.py</code> <pre><code>def split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Split the markdown text into groups of sentences.\n    :param text: The markdown text to split.\n    :return: A list of sentence groups.\n    \"\"\"\n    sentences = re.split(r\"(?&lt;=[.!?])\\s+\", text)\n    sentences = [s.strip() for s in sentences if s.strip()]\n\n    chunks = []\n    for i in range(0, len(sentences), self.num_sentences):\n        chunk = \" \".join(sentences[i : i + self.num_sentences])\n        chunks.append(chunk)\n    return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.paragraph_splitter.ParagraphSplitter","title":"<code>ParagraphSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Split the input text into paragraphs.</p> <p>This class identifies paragraph breaks based on newline characters or other defined delimiters, and splits the text accordingly. Consecutive newline characters are treated as a single break, allowing for clean paragraph extraction.</p> Source code in <code>src/splitter/splitters/paragraph_splitter.py</code> <pre><code>class ParagraphSplitter(BaseSplitter):\n    \"\"\"\n    Split the input text into paragraphs.\n\n    This class identifies paragraph breaks based on newline characters or other defined delimiters,\n    and splits the text accordingly. Consecutive newline characters are treated as a single break,\n    allowing for clean paragraph extraction.\n    \"\"\"\n\n    def __init__(self, num_paragraphs: int = None) -&gt; None:\n        \"\"\"\n        Initialize the ParagraphSplitter.\n\n        Args:\n            num_paragraphs (int, optional): Number of paragraphs per chunk.\n                                            If None, each paragraph is treated as a separate chunk.\n        \"\"\"\n        if num_paragraphs is not None and num_paragraphs &lt;= 0:\n            raise ValueError(\"Number of paragraphs must be greater than 0\")\n        self.num_paragraphs = num_paragraphs\n\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Splits the provided text into paragraphs.\n\n        A paragraph is considered as text separated by one or more newline characters.\n\n        Args:\n            text (str): The text to split.\n\n        Returns:\n            List[str]: A list of text chunks (each chunk is either a single paragraph or a\n                group of paragraphs).\n        \"\"\"\n        # Split text by newlines and filter out empty strings.\n        paragraphs = [p.strip() for p in text.split(\"\\n\") if p.strip()]\n\n        # If num_paragraphs is not specified, return each paragraph separately.\n        if self.num_paragraphs is None:\n            return paragraphs\n\n        # Group paragraphs into chunks of num_paragraphs each.\n        chunks = []\n        for i in range(0, len(paragraphs), self.num_paragraphs):\n            chunk = \"\\n\\n\".join(paragraphs[i : i + self.num_paragraphs])\n            chunks.append(chunk)\n\n        return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.paragraph_splitter.ParagraphSplitter.__init__","title":"<code>__init__(num_paragraphs=None)</code>","text":"<p>Initialize the ParagraphSplitter.</p> <p>Parameters:</p> Name Type Description Default <code>num_paragraphs</code> <code>int</code> <p>Number of paragraphs per chunk.                             If None, each paragraph is treated as a separate chunk.</p> <code>None</code> Source code in <code>src/splitter/splitters/paragraph_splitter.py</code> <pre><code>def __init__(self, num_paragraphs: int = None) -&gt; None:\n    \"\"\"\n    Initialize the ParagraphSplitter.\n\n    Args:\n        num_paragraphs (int, optional): Number of paragraphs per chunk.\n                                        If None, each paragraph is treated as a separate chunk.\n    \"\"\"\n    if num_paragraphs is not None and num_paragraphs &lt;= 0:\n        raise ValueError(\"Number of paragraphs must be greater than 0\")\n    self.num_paragraphs = num_paragraphs\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.paragraph_splitter.ParagraphSplitter.split","title":"<code>split(text)</code>","text":"<p>Splits the provided text into paragraphs.</p> <p>A paragraph is considered as text separated by one or more newline characters.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks (each chunk is either a single paragraph or a group of paragraphs).</p> Source code in <code>src/splitter/splitters/paragraph_splitter.py</code> <pre><code>def split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Splits the provided text into paragraphs.\n\n    A paragraph is considered as text separated by one or more newline characters.\n\n    Args:\n        text (str): The text to split.\n\n    Returns:\n        List[str]: A list of text chunks (each chunk is either a single paragraph or a\n            group of paragraphs).\n    \"\"\"\n    # Split text by newlines and filter out empty strings.\n    paragraphs = [p.strip() for p in text.split(\"\\n\") if p.strip()]\n\n    # If num_paragraphs is not specified, return each paragraph separately.\n    if self.num_paragraphs is None:\n        return paragraphs\n\n    # Group paragraphs into chunks of num_paragraphs each.\n    chunks = []\n    for i in range(0, len(paragraphs), self.num_paragraphs):\n        chunk = \"\\n\\n\".join(paragraphs[i : i + self.num_paragraphs])\n        chunks.append(chunk)\n\n    return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.fixed_splitter.FixedSplitter","title":"<code>FixedSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Split the input text into fixed-size chunks.</p> <p>This class divides the provided text into contiguous substrings, each with a length equal to the specified 'chunk_size'. If the total text length is not an exact multiple of 'chunk_size', the final chunk will contain the remaining characters, which may be shorter than 'chunk_size'.</p> Source code in <code>src/splitter/splitters/fixed_splitter.py</code> <pre><code>class FixedSplitter(BaseSplitter):\n    \"\"\"\n    Split the input text into fixed-size chunks.\n\n    This class divides the provided text into contiguous substrings, each with a length equal to\n    the specified 'chunk_size'. If the total text length is not an exact multiple of 'chunk_size',\n    the final chunk will contain the remaining characters, which may be shorter than 'chunk_size'.\n    \"\"\"\n\n    def __init__(self, size: int = 500) -&gt; None:\n        \"\"\"\n        Initialize the FixedSplitter with a specific chunk size.\n\n        Args:\n            size (int): Number of characters in each chunk.\n        \"\"\"\n        if size &lt;= 0:\n            raise ValueError(\"Chunk size must be greater than 0\")\n        self.size = size\n\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Splits the provided text into chunks, each with a fixed number of characters.\n        If the chunk size is larger than the document size, the entire document is returned\n            as one chunk.\n\n        Args:\n            text (str): The text to split.\n\n        Returns:\n            List[str]: A list of text chunks.\n        \"\"\"\n        if not text:\n            return []\n\n        # Use the document length as effective size if the specified size is\n        # larger.\n        effective_size = self.size if self.size &lt; len(text) else len(text)\n        chunks = [\n            text[i : i + effective_size] for i in range(0, len(text), effective_size)\n        ]\n        return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.fixed_splitter.FixedSplitter.__init__","title":"<code>__init__(size=500)</code>","text":"<p>Initialize the FixedSplitter with a specific chunk size.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of characters in each chunk.</p> <code>500</code> Source code in <code>src/splitter/splitters/fixed_splitter.py</code> <pre><code>def __init__(self, size: int = 500) -&gt; None:\n    \"\"\"\n    Initialize the FixedSplitter with a specific chunk size.\n\n    Args:\n        size (int): Number of characters in each chunk.\n    \"\"\"\n    if size &lt;= 0:\n        raise ValueError(\"Chunk size must be greater than 0\")\n    self.size = size\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.fixed_splitter.FixedSplitter.split","title":"<code>split(text)</code>","text":"<p>Splits the provided text into chunks, each with a fixed number of characters. If the chunk size is larger than the document size, the entire document is returned     as one chunk.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks.</p> Source code in <code>src/splitter/splitters/fixed_splitter.py</code> <pre><code>def split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Splits the provided text into chunks, each with a fixed number of characters.\n    If the chunk size is larger than the document size, the entire document is returned\n        as one chunk.\n\n    Args:\n        text (str): The text to split.\n\n    Returns:\n        List[str]: A list of text chunks.\n    \"\"\"\n    if not text:\n        return []\n\n    # Use the document length as effective size if the specified size is\n    # larger.\n    effective_size = self.size if self.size &lt; len(text) else len(text)\n    chunks = [\n        text[i : i + effective_size] for i in range(0, len(text), effective_size)\n    ]\n    return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.recursive_splitter.RecursiveSplitter","title":"<code>RecursiveSplitter</code>","text":"<p>               Bases: <code>BaseSplitter</code></p> <p>Recursively split the input text into smaller chunks not exceeding a specified maximum length.</p> <p>This class applies a recursive strategy to break down the text into manageable pieces. It first split the text by a fixed number of characters and then further divides any resulting chunk that exceeds 'max_length' until all chunks satisfy the length constraint.</p> Source code in <code>src/splitter/splitters/recursive_splitter.py</code> <pre><code>class RecursiveSplitter(BaseSplitter):\n    \"\"\"\n    Recursively split the input text into smaller chunks not exceeding a specified maximum length.\n\n    This class applies a recursive strategy to break down the text into manageable pieces. It first\n    split the text by a fixed number of characters and then further divides any resulting chunk that\n    exceeds 'max_length' until all chunks satisfy the length constraint.\n    \"\"\"\n\n    def __init__(self, size: int = 500, overlap: int = 25) -&gt; None:\n        \"\"\"\n        Initialize the RecursiveSplitter with a specific chunk size and overlap.\n\n        Args:\n            size (int): The desired number of characters per chunk. Must be greater than 0.\n            overlap (int): The number of overlapping characters between chunks. Must be greater\n                than 0.\n\n        Raises:\n            ValueError: If either size or overlap is less than or equal to 0.\n        \"\"\"\n        if size &lt;= 0 or overlap &lt;= 0:\n            raise ValueError(\n                \"Chunk size and overlap parameters should be greater than 0\"\n            )\n        self.size: int = size\n        self.overlap: int = overlap\n        self.splitter: RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(\n            chunk_size=self.size, chunk_overlap=self.overlap\n        )\n\n    def split(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Splits the provided text into chunks using the recursive splitting strategy.\n        The output from the underlying splitter is converted into a list of strings.\n        If an element has a 'page_content' attribute, that attribute is used; otherwise,\n        the element is assumed to be a string.\n\n        Args:\n            text (str): The input text to split.\n\n        Returns:\n            List[str]: A list of text chunks (strings) resulting from the splitting operation.\n                       Returns an empty list if the input text is empty.\n        \"\"\"\n        if not text:\n            return []\n\n        documents = self.splitter.split_text(text)\n        chunks = [\n            doc if isinstance(doc, str) else doc.page_content for doc in documents\n        ]\n        return chunks\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.recursive_splitter.RecursiveSplitter.__init__","title":"<code>__init__(size=500, overlap=25)</code>","text":"<p>Initialize the RecursiveSplitter with a specific chunk size and overlap.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>The desired number of characters per chunk. Must be greater than 0.</p> <code>500</code> <code>overlap</code> <code>int</code> <p>The number of overlapping characters between chunks. Must be greater than 0.</p> <code>25</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either size or overlap is less than or equal to 0.</p> Source code in <code>src/splitter/splitters/recursive_splitter.py</code> <pre><code>def __init__(self, size: int = 500, overlap: int = 25) -&gt; None:\n    \"\"\"\n    Initialize the RecursiveSplitter with a specific chunk size and overlap.\n\n    Args:\n        size (int): The desired number of characters per chunk. Must be greater than 0.\n        overlap (int): The number of overlapping characters between chunks. Must be greater\n            than 0.\n\n    Raises:\n        ValueError: If either size or overlap is less than or equal to 0.\n    \"\"\"\n    if size &lt;= 0 or overlap &lt;= 0:\n        raise ValueError(\n            \"Chunk size and overlap parameters should be greater than 0\"\n        )\n    self.size: int = size\n    self.overlap: int = overlap\n    self.splitter: RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(\n        chunk_size=self.size, chunk_overlap=self.overlap\n    )\n</code></pre>"},{"location":"splitter/docs/#src.splitter.splitters.recursive_splitter.RecursiveSplitter.split","title":"<code>split(text)</code>","text":"<p>Splits the provided text into chunks using the recursive splitting strategy. The output from the underlying splitter is converted into a list of strings. If an element has a 'page_content' attribute, that attribute is used; otherwise, the element is assumed to be a string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The input text to split.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks (strings) resulting from the splitting operation.        Returns an empty list if the input text is empty.</p> Source code in <code>src/splitter/splitters/recursive_splitter.py</code> <pre><code>def split(self, text: str) -&gt; List[str]:\n    \"\"\"\n    Splits the provided text into chunks using the recursive splitting strategy.\n    The output from the underlying splitter is converted into a list of strings.\n    If an element has a 'page_content' attribute, that attribute is used; otherwise,\n    the element is assumed to be a string.\n\n    Args:\n        text (str): The input text to split.\n\n    Returns:\n        List[str]: A list of text chunks (strings) resulting from the splitting operation.\n                   Returns an empty list if the input text is empty.\n    \"\"\"\n    if not text:\n        return []\n\n    documents = self.splitter.split_text(text)\n    chunks = [\n        doc if isinstance(doc, str) else doc.page_content for doc in documents\n    ]\n    return chunks\n</code></pre>"}]}