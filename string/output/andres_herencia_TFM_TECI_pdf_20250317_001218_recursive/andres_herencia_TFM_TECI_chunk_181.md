Given this work aims for a LLM domain adaption, the QLoRA fine-tuning technique
will be finally employed, only on the query, key, and value projection weights in the
attention layers.

Computational
Cost

Adaptability

Use Case

Method

Prompt
Engineering

RAG

Low

Moderate

Moderate to
High

High

Quick adjustments and
prototyping environments
Tasks require consulting
external knowledge or
up-to-date content
Specific-domain related
tasks with sufficient
computational resources

Fine-tuning