[I] [’m] [the] [fast] [est] [.].

• Tokenization by characters: [D] [o] [n] [’] [t] [w] [a] [s] [t] [e]
[I] [’] [m] [t] [h] [e] [f] [a]

[m] [y] [t] [i] [m] [e] [.]
[s] [t] [e] [s] [t] [.]

• Tokenization by words: [Don’t] [waste] [my] [time] [.]

[I’m] [the]

[fastest] [.].

• Tokenization by sentences: [Don’t waste my time.]

[I’m the fastest.].

E.2 Vectorization. One-hot encoding.