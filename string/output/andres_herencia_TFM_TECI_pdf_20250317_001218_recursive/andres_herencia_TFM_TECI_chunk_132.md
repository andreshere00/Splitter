yt = softmax(z(d)

t W (d) + b(d))

(3.10)

where W (d) is a projection matrix that maps the decoderâ€™s output dimension to the
vocabulary size, and b(d) is a bias term.

22

3.7. LLAMA ARCHITECTURE

3.7 LLaMA architecture