Combining quantization and Low Rank Adapters leverages lower computational com-

plexity. Hence, QLoRA is widely chosen as the fine-tuning method.

4.2.4 Comparison

Despite all three techniques effectively customizing the model for specific use cases, each
method has a different scope. Table 4.1 summarizes these methods based on computa-
tional cost, adaptability, and use case.